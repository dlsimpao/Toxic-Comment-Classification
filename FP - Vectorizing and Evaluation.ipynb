{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/ipynb files/142 Final Project/train.csv')\n",
    "test = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/ipynb files/142 Final Project/test.csv')\n",
    "test_labels = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/ipynb files/142 Final Project/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = pd.read_csv(\"C:/Users/Falak/Desktop/NLP/train.csv\")\n",
    "#test = pd.read_csv(\"C:/Users/Falak/Desktop/NLP/test.csv\")\n",
    "#test_labels = pd.read_csv(\"C:/Users/Falak/Desktop/NLP/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = pd.read_csv('C:/Users/Alvis/STA142A/train.csv')\n",
    "#test = pd.read_csv('C:/Users/Alvis/STA142A/test.csv')\n",
    "#test_labels = pd.read_csv(\"C:/Users/Alvis/STA142A/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>Yo bitch Ja Rule succesful ever whats hating s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>From RfC The title fine IMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>Sources Zawe Ashton Lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>If look back source information I updated corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>I anonymously edit articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>Thank understanding I think highly would rever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "      <td>Please add nonsense Wikipedia Such edits consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>Dear god site horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\n Only a fool can believe in such numbers. ...</td>\n",
       "      <td>Only fool believe numbers The correct number l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\n\\n When fixing double...</td>\n",
       "      <td>Double Redirects When fixing double redirects ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "5  0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...   \n",
       "7  000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "8  00025358d4737918  \" \\n Only a fool can believe in such numbers. ...   \n",
       "9  00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double...   \n",
       "\n",
       "                                               clean  \n",
       "0  Yo bitch Ja Rule succesful ever whats hating s...  \n",
       "1                        From RfC The title fine IMO  \n",
       "2                        Sources Zawe Ashton Lapland  \n",
       "3  If look back source information I updated corr...  \n",
       "4                        I anonymously edit articles  \n",
       "5  Thank understanding I think highly would rever...  \n",
       "6  Please add nonsense Wikipedia Such edits consi...  \n",
       "7                             Dear god site horrible  \n",
       "8  Only fool believe numbers The correct number l...  \n",
       "9  Double Redirects When fixing double redirects ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def preprocess(training, test):\n",
    "    training['clean'] = training.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1) #removes new line character\n",
    "    test['clean'] = test.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1)\n",
    "\n",
    "    #removes urls\n",
    "    training['clean'] = training.apply(lambda row: re.sub('http://\\S+|https://\\S+', '', row['clean']), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub('http://\\S+|https://\\S+', '',row['clean']), axis=1)\n",
    "\n",
    "    #remove all non-alphanumeric values\n",
    "    training['clean'] = training.apply(lambda row: re.sub('[^A-Za-z0-9\\' ]+', '',row['clean']), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub('[^A-Za-z0-9\\' ]+', '',row['clean']), axis=1)\n",
    "\n",
    "    #remove stopwords as they occupy major chunk of the vocabulary\n",
    "    training['clean'] = training['clean'].apply(lambda x: ' '.join([word for word in x.split() if not word in (stop)]))\n",
    "    test['clean'] = test['clean'].apply(lambda x: ' '.join([word for word in x.split() if not word in (stop)]))\n",
    "\n",
    "    #removes all additional spaces\n",
    "    training['clean'] = training.apply(lambda row: re.sub(' +', ' ', row['clean']).strip(), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub(' +', ' ', row['clean']).strip(), axis=1)\n",
    "    \n",
    "    #lowercase end result\n",
    "    training['clean'] = training['clean'].str.lower()\n",
    "    test = test['clean'].str.lower()\n",
    "\n",
    "preprocess(training, test)\n",
    "training.head(10)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without k-fold cross validation\n",
    "# for loop to check the accuracy score for each label\n",
    "\n",
    "for i in range(2,8):\n",
    "    X_train, X_validation = train_test_split(training, random_state = 999) #default is 25% split for validation\n",
    "    Y_train = X_train.iloc[:,i]\n",
    "\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "    tfidf_vectorizer.fit_transform(X_train['clean'].values)\n",
    "\n",
    "    train_feature_set=tfidf_vectorizer.transform(X_train['clean'].values)\n",
    "    test_feature_set=tfidf_vectorizer.transform(X_validation['clean'].values)\n",
    "\n",
    "    scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "    model = scikit_log_reg.fit(train_feature_set, Y_train) #Model build using training data cleaned comments\n",
    "\n",
    "    Y_predicted = model.predict(test_feature_set) #Y_predicted are the predicted labels from our model\n",
    "    Y_predicted_prob = model.predict_proba(test_feature_set) #proba model shows two columns: 1st column is prob that it is classified as 0, 2nd column is prob that it is classified as 1\n",
    "    \n",
    "    #Predicted Accuracy score\n",
    "\n",
    "    Y_validation = X_validation.iloc[:,i]\n",
    "    print(f\"The classification accuracy of the fitted model for the {training.columns[i]} label is {accuracy_score(Y_validation, Y_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold crossvalidation\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf2 = KFold(n_splits = 2)\n",
    "kf = KFold(n_splits = 5)\n",
    "kf10 = KFold(n_splits = 10)\n",
    "\n",
    "#comments -> numbers\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "tfidf_vectorizer.fit_transform(training['clean'].values)\n",
    "\n",
    "#cleaned complete training set\n",
    "training_feature_set = tfidf_vectorizer.transform(training['clean'].values)\n",
    "\n",
    "scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "print(training['toxic'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "def LogRegFit_NoMessage(X, Y, logreg_obj):\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    \n",
    "    model = logreg_obj.fit(X, Y) #Model build using training data cleaned comments\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9593848431156665"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#applied cross validation on one class 'toxic'\n",
    "MSE = []\n",
    "for train_index, valid_index in kf10.split(training_feature_set):\n",
    "    X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "    Y_train, Y_valid = training['toxic'][train_index], training['toxic'][valid_index]\n",
    "    \n",
    "    #Model build using training data cleaned comments\n",
    "    model = LogRegFit_NoMessage(X_train, Y_train, scikit_log_reg)\n",
    "    \n",
    "    # predicted y labels using X validation set\n",
    "    Y_predicted = model.predict(X_valid)\n",
    "    #Y_predicted = model.predict_proba(X_valid)\n",
    "    score = accuracy_score(Y_valid, Y_predicted)\n",
    "    \n",
    "    MSE.append(score)\n",
    "    \n",
    "np.mean(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9593848431156665"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes in feature set and class, returns accuracy score of logistic regression model for that classs\n",
    "def calcClassMSE(FeatureSet, Class):\n",
    "    MSE = []\n",
    "    \n",
    "    for train_index, valid_index in kf10.split(training_feature_set):\n",
    "        X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "        Y_train, Y_valid = training[Class][train_index], training[Class][valid_index] #labels\n",
    "\n",
    "        #Model build using training data cleaned comments\n",
    "        model = LogRegFit_NoMessage(X_train, Y_train, scikit_log_reg) \n",
    "\n",
    "        # predicted y labels using X validation set\n",
    "        Y_predicted = model.predict(X_valid)\n",
    "        #Y_predicted = model.predict_proba(X_valid)\n",
    "        score = accuracy_score(Y_valid, Y_predicted)\n",
    "\n",
    "        MSE.append(score)\n",
    "\n",
    "    return(np.mean(MSE))\n",
    "\n",
    "calcClassMSE(training_feature_set, \"toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "mse_list = {\"toxic\":[],\"severe_toxic\":[],\"obscene\":[],\"threat\":[],\"insult\":[],\"identity_hate\":[]}\n",
    "\n",
    "for c in classes:\n",
    "    mse_list[c].append(calcClassMSE(training_feature_set, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': [0.9593848431156665],\n",
       " 'severe_toxic': [0.9904870003945856],\n",
       " 'obscene': [0.9784672678609574],\n",
       " 'threat': [0.9972864762041469],\n",
       " 'insult': [0.9712040429842066],\n",
       " 'identity_hate': [0.992059954994193]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'threat'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(mse_list, key = mse_list.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "mse_list = {\"toxic\":[],\"severe_toxic\":[],\"obscene\":[],\"threat\":[],\"insult\":[],\"identity_hate\":[]}\n",
    "\n",
    "for c in classes:\n",
    "    mse_list[c].append(calcClassProba(training_feature_set, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer implementation - same as TF-IDF, but returns ints instead of floats. Makes MSE slightly lower but just because of integer rounding most likely\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "kf10 = KFold(n_splits = 10)\n",
    "\n",
    "#comments -> numbers\n",
    "cv = CountVectorizer(binary = True, max_df = 0.7)\n",
    "cv.fit_transform(training['clean'].values)\n",
    "\n",
    "#cleaned complete training set\n",
    "training_feature_set_binary = cv.transform(training['clean'].values)\n",
    "\n",
    "scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "\n",
    "MSE = []\n",
    "for train_index, valid_index in kf10.split(training_feature_set_binary):\n",
    "    X_train, X_valid = training_feature_set_binary[train_index], training_feature_set_binary[valid_index]\n",
    "    Y_train, Y_valid = training['toxic'][train_index], training['toxic'][valid_index]\n",
    "    \n",
    "    model = scikit_log_reg.fit(X_train, Y_train) #Model build using training data cleaned comments\n",
    "\n",
    "    # predicted y labels using X validation set\n",
    "    Y_predicted = model.predict(X_valid)\n",
    "    #Y_predicted = model.predict_proba(X_valid)\n",
    "    score = accuracy_score(Y_valid, Y_predicted)\n",
    "    \n",
    "    MSE.append(score)\n",
    " \n",
    "np.mean(MSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
