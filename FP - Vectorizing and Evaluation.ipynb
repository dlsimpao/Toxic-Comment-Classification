{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/ipynb files/142 Final Project/train.csv')\n",
    "test = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/ipynb files/142 Final Project/test.csv')\n",
    "test_labels = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/ipynb files/142 Final Project/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = pd.read_csv(\"C:/Users/Falak/Desktop/NLP/train.csv\")\n",
    "#test = pd.read_csv(\"C:/Users/Falak/Desktop/NLP/test.csv\")\n",
    "#test_labels = pd.read_csv(\"C:/Users/Falak/Desktop/NLP/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('C:/Users/Alvis/STA142A/train.csv')\n",
    "test = pd.read_csv('C:/Users/Alvis/STA142A/test.csv')\n",
    "test_labels = pd.read_csv(\"C:/Users/Alvis/STA142A/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why edits made username hardcore m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he matches background colour i'm seeming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i'm really trying edit war it's guy co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can't make real suggestions improvement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir hero any chance remember page that's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulations well use tools well talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>your vandalism matt shirvington article revert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry word 'nonsense' offensive anyway i'm int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "5             0        0       0       0              0   \n",
       "6             1        1       0       1              0   \n",
       "7             0        0       0       0              0   \n",
       "8             0        0       0       0              0   \n",
       "9             0        0       0       0              0   \n",
       "\n",
       "                                               clean  \n",
       "0  explanation why edits made username hardcore m...  \n",
       "1  d'aww he matches background colour i'm seeming...  \n",
       "2  hey man i'm really trying edit war it's guy co...  \n",
       "3  more i can't make real suggestions improvement...  \n",
       "4       you sir hero any chance remember page that's  \n",
       "5           congratulations well use tools well talk  \n",
       "6       cocksucker before you piss around on my work  \n",
       "7  your vandalism matt shirvington article revert...  \n",
       "8  sorry word 'nonsense' offensive anyway i'm int...  \n",
       "9               alignment subject contrary dulithgow  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def preprocess(training, test):\n",
    "    training['clean'] = training.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1) #removes new line character\n",
    "    test['clean'] = test.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1)\n",
    "\n",
    "    #removes urls\n",
    "    training['clean'] = training.apply(lambda row: re.sub('http://\\S+|https://\\S+', '', row['clean']), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub('http://\\S+|https://\\S+', '',row['clean']), axis=1)\n",
    "\n",
    "    #remove all non-alphanumeric values\n",
    "    training['clean'] = training.apply(lambda row: re.sub('[^A-Za-z0-9\\' ]+', '',row['clean']), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub('[^A-Za-z0-9\\' ]+', '',row['clean']), axis=1)\n",
    "\n",
    "    #remove stopwords as they occupy major chunk of the vocabulary\n",
    "    training['clean'] = training['clean'].apply(lambda x: ' '.join([word for word in x.split() if not word in (stop)]))\n",
    "    test['clean'] = test['clean'].apply(lambda x: ' '.join([word for word in x.split() if not word in (stop)]))\n",
    "\n",
    "    #removes all additional spaces\n",
    "    training['clean'] = training.apply(lambda row: re.sub(' +', ' ', row['clean']).strip(), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub(' +', ' ', row['clean']).strip(), axis=1)\n",
    "    \n",
    "    #lowercase end result\n",
    "    training['clean'] = training['clean'].str.lower()\n",
    "    test = test['clean'].str.lower()\n",
    "\n",
    "preprocess(training, test)\n",
    "training.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without k-fold cross validation\n",
    "# for loop to check the accuracy score for each label\n",
    "\n",
    "for i in range(2,8):\n",
    "    X_train, X_validation = train_test_split(training, random_state = 999) #default is 25% split for validation\n",
    "    Y_train = X_train.iloc[:,i]\n",
    "\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "    tfidf_vectorizer.fit_transform(X_train['clean'].values)\n",
    "\n",
    "    train_feature_set=tfidf_vectorizer.transform(X_train['clean'].values)\n",
    "    test_feature_set=tfidf_vectorizer.transform(X_validation['clean'].values)\n",
    "\n",
    "    scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "    model = scikit_log_reg.fit(train_feature_set, Y_train) #Model build using training data cleaned comments\n",
    "\n",
    "    Y_predicted = model.predict(test_feature_set) #Y_predicted are the predicted labels from our model\n",
    "    Y_predicted_prob = model.predict_proba(test_feature_set) #proba model shows two columns: 1st column is prob that it is classified as 0, 2nd column is prob that it is classified as 1\n",
    "    \n",
    "    #Predicted Accuracy score\n",
    "\n",
    "    Y_validation = X_validation.iloc[:,i]\n",
    "    print(f\"The classification accuracy of the fitted model for the {training.columns[i]} label is {accuracy_score(Y_validation, Y_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x235885 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4679912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k fold crossvalidation\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf2 = KFold(n_splits = 2)\n",
    "kf = KFold(n_splits = 5)\n",
    "kf10 = KFold(n_splits = 10)\n",
    "\n",
    "#comments -> numbers\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "tfidf_vectorizer.fit_transform(training['clean'].values)\n",
    "\n",
    "#cleaned complete training set\n",
    "training_feature_set = tfidf_vectorizer.transform(training['clean'].values)\n",
    "\n",
    "scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "training_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': [0.89125],\n",
       " 'severe_toxic': [0.9889000000000001],\n",
       " 'obscene': [0.9460000000000001],\n",
       " 'threat': [0.99665],\n",
       " 'insult': [0.9489000000000001],\n",
       " 'identity_hate': [0.9909500000000001]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NEW CHUNK - kNN implementation with sample of data\n",
    "import sys, os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#comments -> numbers\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "tfidf_vectorizer.fit_transform(training['clean'].values)\n",
    "\n",
    "#cleaned complete training set - sampled for 20000 observations since KNN is slow\n",
    "training_feature_set = tfidf_vectorizer.transform(np.random.choice(training['clean'].values, 20000))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5) #5-neighbors becasue KNN is slow\n",
    "\n",
    "def kNNFit_NoMessage(X, Y, knn_obj):\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    \n",
    "    model = knn_obj.fit(X, Y) #Model build using training data cleaned comments\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "def calckNNMSE(FeatureSet, Class):\n",
    "    MSE = []\n",
    "    \n",
    "    for train_index, valid_index in kf.split(training_feature_set): #5-folds because KNN is slow\n",
    "        X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "        Y_train, Y_valid = training[Class][train_index], training[Class][valid_index] #labels\n",
    "\n",
    "        #Model build using training data cleaned comments\n",
    "        model = kNNFit_NoMessage(X_train, Y_train, knn) \n",
    "\n",
    "        # predicted y labels using X validation set\n",
    "        Y_predicted = model.predict(X_valid)\n",
    "        #Y_predicted = model.predict_proba(X_valid)\n",
    "        score = accuracy_score(Y_valid, Y_predicted)\n",
    "\n",
    "        MSE.append(score)\n",
    "\n",
    "    return(np.mean(MSE))\n",
    "\n",
    "classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "mse_list = {\"toxic\":[],\"severe_toxic\":[],\"obscene\":[],\"threat\":[],\"insult\":[],\"identity_hate\":[]}\n",
    "\n",
    "for c in classes:\n",
    "    mse_list[c].append(calckNNMSE(training_feature_set, c))\n",
    "    \n",
    "mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': [0.9029],\n",
       " 'severe_toxic': [0.9899000000000001],\n",
       " 'obscene': [0.9473],\n",
       " 'threat': [0.9967],\n",
       " 'insult': [0.9505999999999999],\n",
       " 'identity_hate': [0.9916]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NEW CHUNK - svm implementation\n",
    "import sys, os\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#comments -> numbers\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "tfidf_vectorizer.fit_transform(training['clean'].values)\n",
    "\n",
    "#cleaned complete training set\n",
    "training_feature_set = tfidf_vectorizer.transform(np.random.choice(training['clean'].values, 10000))\n",
    "\n",
    "svm = SVC(kernel = \"linear\", C = 0.25, random_state = 999)\n",
    "\n",
    "def svmFit_NoMessage(X, Y, svm_obj):\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    \n",
    "    model = svm_obj.fit(X, Y) #Model build using training data cleaned comments\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "def calcsvmMSE(FeatureSet, Class):\n",
    "    MSE = []\n",
    "    \n",
    "    for train_index, valid_index in kf.split(training_feature_set): #kf = 5 folds\n",
    "        X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "        Y_train, Y_valid = training[Class][train_index], training[Class][valid_index] #labels\n",
    "\n",
    "        #Model build using training data cleaned comments\n",
    "        model = svmFit_NoMessage(X_train, Y_train, svm) \n",
    "\n",
    "        # predicted y labels using X validation set\n",
    "        Y_predicted = model.predict(X_valid)\n",
    "        #Y_predicted = model.predict_proba(X_valid)\n",
    "        score = accuracy_score(Y_valid, Y_predicted)\n",
    "\n",
    "        MSE.append(score)\n",
    "\n",
    "    return(np.mean(MSE))\n",
    "\n",
    "classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "mse_list = {\"toxic\":[],\"severe_toxic\":[],\"obscene\":[],\"threat\":[],\"insult\":[],\"identity_hate\":[]}\n",
    "\n",
    "for c in classes:\n",
    "    mse_list[c].append(calcsvmMSE(training_feature_set, c))\n",
    "    \n",
    "mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': [0.90105],\n",
       " 'severe_toxic': [0.9889000000000001],\n",
       " 'obscene': [0.9461],\n",
       " 'threat': [0.99665],\n",
       " 'insult': [0.9488],\n",
       " 'identity_hate': [0.99095]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes in feature set and class, returns accuracy score of logistic regression model for that class\n",
    "import sys, os\n",
    "def LogRegFit_NoMessage(X, Y, logreg_obj):\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    \n",
    "    model = logreg_obj.fit(X, Y) #Model build using training data cleaned comments\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "def calcClassMSE(FeatureSet, Class):\n",
    "    MSE = []\n",
    "    \n",
    "    for train_index, valid_index in kf10.split(training_feature_set):\n",
    "        X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "        Y_train, Y_valid = training[Class][train_index], training[Class][valid_index] #labels\n",
    "\n",
    "        #Model build using training data cleaned comments\n",
    "        model = LogRegFit_NoMessage(X_train, Y_train, scikit_log_reg) \n",
    "\n",
    "        # predicted y labels using X validation set\n",
    "        Y_predicted = model.predict(X_valid)\n",
    "        #Y_predicted = model.predict_proba(X_valid)\n",
    "        score = accuracy_score(Y_valid, Y_predicted)\n",
    "\n",
    "        MSE.append(score)\n",
    "\n",
    "    return(np.mean(MSE))\n",
    "\n",
    "classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "mse_list = {\"toxic\":[],\"severe_toxic\":[],\"obscene\":[],\"threat\":[],\"insult\":[],\"identity_hate\":[]}\n",
    "\n",
    "for c in classes:\n",
    "    mse_list[c].append(calcClassMSE(training_feature_set, c))\n",
    "    \n",
    "mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'threat'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applied cross validation on one class 'toxic'\n",
    "MSE = []\n",
    "for train_index, valid_index in kf10.split(training_feature_set):\n",
    "    X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "    Y_train, Y_valid = training['toxic'][train_index], training['toxic'][valid_index]\n",
    "    \n",
    "    #Model build using training data cleaned comments\n",
    "    model = LogRegFit_NoMessage(X_train, Y_train, scikit_log_reg)\n",
    "    \n",
    "    # predicted y labels using X validation set\n",
    "    Y_predicted = model.predict(X_valid)\n",
    "    #Y_predicted = model.predict_proba(X_valid)\n",
    "    score = accuracy_score(Y_valid, Y_predicted)\n",
    "    \n",
    "    MSE.append(score)\n",
    "    \n",
    "np.mean(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "mse_list = {\"toxic\":[],\"severe_toxic\":[],\"obscene\":[],\"threat\":[],\"insult\":[],\"identity_hate\":[]}\n",
    "\n",
    "for c in classes:\n",
    "    mse_list[c].append(calcClassProba(training_feature_set, c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
