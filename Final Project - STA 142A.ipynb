{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/142 Final Project/train.csv')\n",
    "test = pd.read_csv('C:/Users/dlsim/Documents/_College/1 UC Davis/4 Senior Year/Win - STA 142a - Statistical Learning I/142 Final Project/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data dimensions are (159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training = pd.read_csv(\"C:/Users/Alvis/STA142A/train.csv\")\n",
    "#test = pd.read_csv(\"C:/Users/Alvis/STA142A/test.csv\")\n",
    "#test_labels = pd.read_csv(\"C:/Users/Alvis/STA142A/test_labels.csv\")\n",
    "\n",
    "print(f\"Train Data dimensions are {training.shape}\")\n",
    "#print(f\"Train Data dimensions are {test.shape}\")\n",
    "\n",
    "training.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>Type of Comment Violation</th>\n",
       "      <th>Number of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>15294</td>\n",
       "      <td>toxic</td>\n",
       "      <td>15294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>1595</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>8449</td>\n",
       "      <td>obscene</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>478</td>\n",
       "      <td>threat</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>7877</td>\n",
       "      <td>insult</td>\n",
       "      <td>7877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>1405</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index      0 Type of Comment Violation  Number of Comments\n",
       "0          toxic  15294                     toxic               15294\n",
       "1   severe_toxic   1595              severe_toxic                1595\n",
       "2        obscene   8449                   obscene                8449\n",
       "3         threat    478                    threat                 478\n",
       "4         insult   7877                    insult                7877\n",
       "5  identity_hate   1405             identity_hate                1405"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization - https://www.kaggle.com/sasidharturaga/eda-step-wise-preprocess-and-lstm-classifier\n",
    "import plotly.express as px\n",
    "\n",
    "df1 = pd.DataFrame(training[training.columns[2:]].sum(axis=0)).reset_index() \n",
    "df1[\"Type of Comment Violation\"] = df1[\"index\"]\n",
    "df1[\"Number of Comments\"] = df1[0]\n",
    "df1.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>Number of Types of Violations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143346</td>\n",
       "      <td>143346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6360</td>\n",
       "      <td>6360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4209</td>\n",
       "      <td>4209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3480</td>\n",
       "      <td>3480</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1760</td>\n",
       "      <td>1760</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>385</td>\n",
       "      <td>385</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  Number of Sentences  Number of Types of Violations\n",
       "0  143346               143346                              0\n",
       "1    6360                 6360                              1\n",
       "3    4209                 4209                              3\n",
       "2    3480                 3480                              2\n",
       "4    1760                 1760                              4\n",
       "5     385                  385                              5\n",
       "6      31                   31                              6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(pd.DataFrame(training[training.columns[2:]].sum(axis=1)).reset_index()[0].value_counts())\n",
    "df2[\"Number of Sentences\"]=df2[0]\n",
    "df2[\"Number of Types of Violations\"]=df2.index\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display of comments \n",
    "df1 = df1.sort_values(0, ascending=False) \n",
    "fig1 = px.bar(df1, x=\"Type of Comment Violation\", y=\"Number of Comments\", title=\"No. of comments per label\",text=\"Number of Comments\")\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.bar(df2, x=\"Number of Types of Violations\", y=\"Number of Sentences\", title=\"Number of Comments by Amount of Labels\", text=\"Number of Sentences\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "words = ' '.join([text for text in training['comment_text']])\n",
    "\n",
    "word_cloud = WordCloud(\n",
    "                       width=1600,\n",
    "                       height=800,\n",
    "                       colormap='PuRd', \n",
    "                       margin=0,\n",
    "                       max_words=500, # Maximum numbers of words we want to see \n",
    "                       min_word_length=3, # Minimum numbers of letters of each word to be part of the cloud\n",
    "                       max_font_size=150, min_font_size=30,  # Font size range\n",
    "                       background_color=\"white\").generate(words)\n",
    "\n",
    "plt.figure(figsize=(10, 16))\n",
    "plt.imshow(word_cloud, interpolation=\"gaussian\")\n",
    "plt.title(\"Training Comments Word Cloud\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join([text for text in test['comment_text']])\n",
    "\n",
    "word_cloud = WordCloud(\n",
    "                       width=1600,\n",
    "                       height=800,\n",
    "                       colormap='BuGn', \n",
    "                       margin=0,\n",
    "                       max_words=500, # Maximum numbers of words we want to see \n",
    "                       min_word_length=3, # Minimum numbers of letters of each word to be part of the cloud\n",
    "                       max_font_size=150, min_font_size=30,  # Font size range\n",
    "                       background_color=\"white\").generate(words)\n",
    "\n",
    "plt.figure(figsize=(10, 16))\n",
    "plt.imshow(word_cloud, interpolation=\"gaussian\")\n",
    "plt.title(\"Test Comments Word Cloud\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def preprocess(training, test):\n",
    "    training['clean'] = training.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1) #removes new line character\n",
    "    test['clean'] = test.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1)\n",
    "\n",
    "    #removes urls\n",
    "    training['clean'] = training.apply(lambda row: re.sub('http://\\S+|https://\\S+', '', row['clean']), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub('http://\\S+|https://\\S+', '',row['clean']), axis=1)\n",
    "\n",
    "    #remove all non-alphanumeric values\n",
    "    training['clean'] = training.apply(lambda row: re.sub('[^A-Za-z0-9\\' ]+', '',row['clean']), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub('[^A-Za-z0-9\\' ]+', '',row['clean']), axis=1)\n",
    "\n",
    "    #remove stopwords as they occupy major chunk of the vocabulary\n",
    "    training['clean'] = training['clean'].apply(lambda x: ' '.join([word for word in x.split() if not word in (stop)]))\n",
    "    test['clean'] = test['clean'].apply(lambda x: ' '.join([word for word in x.split() if not word in (stop)]))\n",
    "\n",
    "    #removes all additional spaces\n",
    "    training['clean'] = training.apply(lambda row: re.sub(' +', ' ', row['clean']).strip(), axis=1)\n",
    "    test['clean'] = test.apply(lambda row: re.sub(' +', ' ', row['clean']).strip(), axis=1)\n",
    "    \n",
    "    #lowercase end result\n",
    "    training['clean'] = training['clean'].str.lower()\n",
    "    test = test['clean'].str.lower()\n",
    "\n",
    "preprocess(training, test)\n",
    "training.head(10)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigram analysis - see https://www.kaggle.com/swathi314/toxic-comments-exploratory-analysis-baseline#Toxic-comment-classification\n",
    "#need to rewrite two functions, gram_analysis and gram_freq to generate result below\n",
    "for i in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'clean']:\n",
    "    gram_freq(training,2, i, 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "#Split training dataset into train_data and test_data. Vectorize both train_data and test_data, then build model around \n",
    "# train_data to predict values for test_data. Compare predicted test_data values against real test_data values to get an\n",
    "# accuracy score.\n",
    "\n",
    "X_train = training['clean']\n",
    "X_test = test['clean']\n",
    "Y_train = training['toxic']\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "tfidf_vectorizer.fit_transform(X_train.values)\n",
    "        \n",
    "train_feature_set=tfidf_vectorizer.transform(X_train.values)\n",
    "test_feature_set=tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "model=scikit_log_reg.fit(train_feature_set, Y_train) #Model build using training data cleaned comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "X_train, X_validation = train_test_split(training, random_state = 999) #default is 25% split for validation\n",
    "Y_train = X_train['toxic']\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "tfidf_vectorizer.fit_transform(X_train['clean'].values)\n",
    "\n",
    "train_feature_set=tfidf_vectorizer.transform(X_train['clean'].values)\n",
    "test_feature_set=tfidf_vectorizer.transform(X_validation['clean'].values)\n",
    "\n",
    "scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "model = scikit_log_reg.fit(train_feature_set, Y_train) #Model build using training data cleaned comments\n",
    "\n",
    "Y_predicted = model.predict(test_feature_set) #Y_predicted are the predicted labels from our model\n",
    "Y_predicted_prob = model.predict_proba(test_feature_set) #proba model shows two columns: 1st column is prob that it is classified as 0, 2nd column is prob that it is classified as 1\n",
    "#print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]The classification accuracy of the fitted model for the toxic label is 0.9603940540947034\n",
      "[LibLinear]The classification accuracy of the fitted model for the severe_toxic label is 0.990449452284862\n",
      "[LibLinear]The classification accuracy of the fitted model for the obscene label is 0.9790439425463113\n",
      "[LibLinear]The classification accuracy of the fitted model for the threat label is 0.9970922216930288\n",
      "[LibLinear]The classification accuracy of the fitted model for the insult label is 0.9720502343769584\n",
      "[LibLinear]The classification accuracy of the fitted model for the identity_hate label is 0.9922793472539042\n"
     ]
    }
   ],
   "source": [
    "# NEW CODE\n",
    "# for loop to check the accuracy score for each label\n",
    "\n",
    "for i in range(2,8):\n",
    "    X_train, X_validation = train_test_split(training, random_state = 999) #default is 25% split for validation\n",
    "    Y_train = X_train.iloc[:,i]\n",
    "\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "    tfidf_vectorizer.fit_transform(X_train['clean'].values)\n",
    "\n",
    "    train_feature_set=tfidf_vectorizer.transform(X_train['clean'].values)\n",
    "    test_feature_set=tfidf_vectorizer.transform(X_validation['clean'].values)\n",
    "\n",
    "    scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "    model = scikit_log_reg.fit(train_feature_set, Y_train) #Model build using training data cleaned comments\n",
    "\n",
    "    Y_predicted = model.predict(test_feature_set) #Y_predicted are the predicted labels from our model\n",
    "    Y_predicted_prob = model.predict_proba(test_feature_set) #proba model shows two columns: 1st column is prob that it is classified as 0, 2nd column is prob that it is classified as 1\n",
    "    \n",
    "    #Predicted Accuracy score\n",
    "\n",
    "    Y_validation = X_validation.iloc[:,i]\n",
    "    print(f\"The classification accuracy of the fitted model for the {training.columns[i]} label is {accuracy_score(Y_validation, Y_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW CODE\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "kf10 = KFold(n_splits = 10)\n",
    "\n",
    "#comments -> numbers\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.7) #Vectorization of training cleaned comments\n",
    "tfidf_vectorizer.fit_transform(training['clean'].values)\n",
    "\n",
    "#cleaned complete training set\n",
    "training_feature_set = tfidf_vectorizer.transform(training['clean'].values)\n",
    "\n",
    "#logistic regression obj\n",
    "scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(training['toxic'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9601556533101245"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NEW CODE\n",
    "MSE = []\n",
    "for train_index, valid_index in kf10.split(training_feature_set):\n",
    "    X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "    Y_train, Y_valid = training['toxic'][train_index], training['toxic'][valid_index]\n",
    "    \n",
    "    model = scikit_log_reg.fit(X_train, Y_train) #Model build using training data cleaned comments\n",
    "    \n",
    "    # predicted y labels using X validation set\n",
    "    Y_predicted = model.predict(X_valid)\n",
    "    #Y_predicted = model.predict_proba(X_valid)\n",
    "    score = accuracy_score(Y_valid, Y_predicted)\n",
    "    \n",
    "    MSE.append(score)\n",
    "    \n",
    "np.mean(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcClassMSE(FeatureSet, Class):\n",
    "    MSE = []\n",
    "    \n",
    "    for train_index, valid_index in kf10.split(training_feature_set):\n",
    "        X_train, X_valid = training_feature_set[train_index], training_feature_set[valid_index]\n",
    "        Y_train, Y_valid = training[Class][train_index], training[Class][valid_index] #labels\n",
    "\n",
    "        model = scikit_log_reg.fit(X_train, Y_train) #Model build using training data cleaned comments\n",
    "\n",
    "        # predicted y labels using X validation set\n",
    "        Y_predicted = model.predict(X_valid)\n",
    "        #Y_predicted = model.predict_proba(X_valid)\n",
    "        score = accuracy_score(Y_valid, Y_predicted)\n",
    "\n",
    "        MSE.append(score)\n",
    "\n",
    "    return(np.mean(MSE))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "calcClassMSE(training_feature_set, \"toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.960584033086853,\n",
       " 0.9562574418750391,\n",
       " 0.9607068997931942,\n",
       " 0.9592655261013975,\n",
       " 0.9587015103089553,\n",
       " 0.9594535313655449,\n",
       " 0.9600802155793695,\n",
       " 0.9606442313718118,\n",
       " 0.9588268471517203,\n",
       " 0.95932819452278]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted Accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "Y_validation = X_validation['toxic']\n",
    "\n",
    "print(accuracy_score(Y_validation, Y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-ab6a1037256d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-ab6a1037256d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    - Run Block 121 for the other 5 labels and test accuracy score\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#To Do:\n",
    "- Run Block 121 for the other 5 labels and test accuracy score\n",
    "- Test for test data? using the labels \n",
    "- Bi-gram post-processing data analysis\n",
    "- Change cross-validation for subsetting data\n",
    "- Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#References\n",
    "\n",
    "#Stop words: https://stackabuse.com/removing-stop-words-from-strings-in-python/\n",
    "#Remove additional spaces: https://stackoverflow.com/questions/1546226/is-there-a-simple-way-to-remove-multiple-spaces-in-a-string\n",
    "#Classification (Logistic): https://kavita-ganesan.com/news-classifier-with-logistic-regression-in-python/#.YE01E50zZPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
